# Uni-GCN ä½¿ç”¨æŒ‡å—

## ğŸ¯ å¦‚ä½•ä½¿ç”¨è‡ªå®šä¹‰å…³é”®ç‚¹æ ¼å¼

### 1. ä½¿ç”¨COCO-Wholebodyæ ¼å¼

```python
import torch
from uni_GCN import UniSTGCN

# åˆ›å»ºæ”¯æŒCOCO-Wholebodyçš„æ¨¡å‹
model = UniSTGCN(
    parts=[
        ('coco_wholebody', 'body'),       # COCOèº«ä½“17ä¸ªå…³é”®ç‚¹
        ('coco_wholebody', 'left_hand'),  # å·¦æ‰‹21ä¸ªå…³é”®ç‚¹
        ('coco_wholebody', 'right_hand'), # å³æ‰‹21ä¸ªå…³é”®ç‚¹
        ('coco_wholebody', 'face')        # é¢éƒ¨68ä¸ªå…³é”®ç‚¹
    ],
    keypoint_format='coco_wholebody',
    auto_convert=True,  # è‡ªåŠ¨ä»å®Œæ•´æ•°æ®ä¸­æå–éƒ¨ä½
    hidden_dim=64
)

# COCO-Wholebodyæ•°æ® (133ä¸ªå…³é”®ç‚¹)
coco_data = torch.randn(batch_size, seq_len, 133, 3)

# ç›´æ¥è¾“å…¥å®Œæ•´æ•°æ®ï¼Œæ¨¡å‹è‡ªåŠ¨æå–æ‰€éœ€éƒ¨ä½
output = model(coco_data)
```

### 2. ä½¿ç”¨MediaPipeæ ¼å¼

```python
# MediaPipe Holisticæ ¼å¼ (543ä¸ªå…³é”®ç‚¹)
model = UniSTGCN(
    parts=[
        ('mediapipe_holistic', 'body'),
        ('mediapipe_holistic', 'left_hand'),
        ('mediapipe_holistic', 'right_hand')
    ],
    keypoint_format='mediapipe_holistic',
    auto_convert=True
)

# MediaPipeæ•°æ®
mp_data = torch.randn(batch_size, seq_len, 543, 3)
output = model(mp_data)
```

### 3. åˆ›å»ºè‡ªå®šä¹‰æ ¼å¼

```python
from uni_GCN import create_custom_format, UniSTGCN

# å®šä¹‰ä½ çš„è‡ªå®šä¹‰æ ¼å¼
custom_format = create_custom_format(
    name="my_custom_format",
    parts_config={
        'torso': list(range(10)),        # å…³é”®ç‚¹ç´¢å¼•0-9
        'left_arm': list(range(10, 20)), # å…³é”®ç‚¹ç´¢å¼•10-19
        'right_arm': list(range(20, 30)) # å…³é”®ç‚¹ç´¢å¼•20-29
    },
    connections_config={
        'torso': [[0,1], [1,2], [2,3]],     # è¿æ¥å…³ç³»
        'left_arm': [[0,1], [1,2], [2,3]],
        'right_arm': [[0,1], [1,2], [2,3]]
    },
    centers_config={
        'torso': 5,      # ä¸­å¿ƒç‚¹ç´¢å¼•
        'left_arm': 5,
        'right_arm': 5
    }
)

# ä½¿ç”¨è‡ªå®šä¹‰æ ¼å¼
model = UniSTGCN(
    parts=[
        ('my_custom_format', 'torso'),
        ('my_custom_format', 'left_arm'),
        ('my_custom_format', 'right_arm')
    ],
    keypoint_format=custom_format,
    auto_convert=True
)
```

### 4. æ ¼å¼è½¬æ¢

```python
from uni_GCN import KeypointConverter, convert_coco_to_unisign

# æ–¹æ³•1: ç›´æ¥è½¬æ¢å‡½æ•°
coco_data = torch.randn(2, 64, 133, 3)
unisign_parts = convert_coco_to_unisign(coco_data)

# æ–¹æ³•2: ä½¿ç”¨è½¬æ¢å™¨
converter = KeypointConverter('coco_wholebody')

# æå–ç‰¹å®šéƒ¨ä½
body_keypoints = converter.extract_part(coco_data, 'body')
left_hand = converter.extract_part(coco_data, 'left_hand')

# å½’ä¸€åŒ–ï¼ˆç›¸å¯¹äºä¸­å¿ƒç‚¹ï¼‰
left_hand_normalized = converter.normalize_part(
    left_hand, 'left_hand', method='center'
)
```

## ğŸ”§ é«˜çº§é…ç½®

### å›¾æ„å»ºç­–ç•¥

```python
model = UniSTGCN(
    parts=[('coco_wholebody', 'body')],
    graph_strategy='spatial',  # 'uniform', 'distance', 'spatial'
    adaptive_graph=True,       # å¯å­¦ä¹ çš„é‚»æ¥çŸ©é˜µ
    max_hop=2                 # æœ€å¤§è·³æ•°
)
```

### éƒ¨ä½äº¤äº’

```python
# æ¨¡å‹ä¼šè‡ªåŠ¨å¤„ç†éƒ¨ä½é—´çš„äº¤äº’ï¼š
# - å·¦æ‰‹ç‰¹å¾ += å·¦æ‰‹è…•çš„èº«ä½“ç‰¹å¾
# - å³æ‰‹ç‰¹å¾ += å³æ‰‹è…•çš„èº«ä½“ç‰¹å¾
# - é¢éƒ¨ç‰¹å¾ += å¤´éƒ¨çš„èº«ä½“ç‰¹å¾

model = UniSTGCN(
    parts=[
        ('coco_wholebody', 'body'),      # å¿…é¡»åŒ…å«bodyæ‰èƒ½è¿›è¡Œéƒ¨ä½äº¤äº’
        ('coco_wholebody', 'left_hand'),
        ('coco_wholebody', 'right_hand')
    ],
    keypoint_format='coco_wholebody'
)
```

## ğŸš€ å®é™…åº”ç”¨ç¤ºä¾‹

### æ‰‹è¯­è¯†åˆ«ç³»ç»Ÿ

```python
class SignLanguageRecognizer(nn.Module):
    def __init__(self, num_classes, input_format='coco_wholebody'):
        super().__init__()
        self.stgcn = UniSTGCN(
            parts=[
                (input_format, 'body'),
                (input_format, 'left_hand'),
                (input_format, 'right_hand')
            ],
            keypoint_format=input_format,
            auto_convert=True
        )
        self.classifier = nn.Linear(self.stgcn.get_output_dim(), num_classes)

    def forward(self, keypoints):
        # keypoints: (batch, time, total_points, 3)
        features = self.stgcn(keypoints)          # (batch, time, feature_dim)
        pooled = features.mean(dim=1)             # (batch, feature_dim)
        logits = self.classifier(pooled)          # (batch, num_classes)
        return logits

# ä½¿ç”¨
model = SignLanguageRecognizer(num_classes=100, input_format='coco_wholebody')
coco_keypoints = torch.randn(4, 64, 133, 3)
predictions = model(coco_keypoints)
```

### å¤šæ¨¡æ€èåˆ

```python
class MultiModalSTGCN(nn.Module):
    def __init__(self):
        super().__init__()
        # ä¸åŒæ ¼å¼çš„æ•°æ®ä½¿ç”¨ä¸åŒæ¨¡å‹
        self.coco_model = UniSTGCN(
            parts=[('coco_wholebody', 'body'), ('coco_wholebody', 'left_hand')],
            keypoint_format='coco_wholebody',
            auto_convert=True
        )

        self.mediapipe_model = UniSTGCN(
            parts=[('mediapipe_holistic', 'body'), ('mediapipe_holistic', 'face')],
            keypoint_format='mediapipe_holistic',
            auto_convert=True
        )

        self.fusion = nn.Linear(self.coco_model.get_output_dim() +
                               self.mediapipe_model.get_output_dim(), 512)

    def forward(self, coco_data, mediapipe_data):
        coco_features = self.coco_model(coco_data)
        mp_features = self.mediapipe_model(mediapipe_data)

        combined = torch.cat([coco_features, mp_features], dim=-1)
        return self.fusion(combined)
```

## ğŸ› å¸¸è§é—®é¢˜

### Q: å¦‚ä½•å¤„ç†ä¸åŒé•¿åº¦çš„åºåˆ—ï¼Ÿ
```python
# ä½¿ç”¨padding
from torch.nn.utils.rnn import pad_sequence

def collate_fn(batch):
    # batch: list of (keypoints, label)
    keypoints = [item[0] for item in batch]
    labels = [item[1] for item in batch]

    # Padåºåˆ—åˆ°ç›¸åŒé•¿åº¦
    padded_keypoints = pad_sequence(keypoints, batch_first=True, padding_value=0)

    return padded_keypoints, torch.stack(labels)
```

### Q: å¦‚ä½•å¤„ç†ç¼ºå¤±çš„å…³é”®ç‚¹ï¼Ÿ
```python
# åœ¨å…³é”®ç‚¹æ•°æ®ä¸­ï¼Œç½®ä¿¡åº¦ä¸º0è¡¨ç¤ºç¼ºå¤±
keypoints = torch.randn(2, 64, 133, 3)
keypoints[:, :, :, 2] = torch.where(
    torch.rand_like(keypoints[:, :, :, 2]) > 0.1,  # 90%çš„ç‚¹æœ‰æ•ˆ
    keypoints[:, :, :, 2],
    torch.zeros_like(keypoints[:, :, :, 2])  # 10%çš„ç‚¹ç¼ºå¤±
)
```

### Q: å¦‚ä½•å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹ï¼Ÿ
```python
# åŠ è½½é¢„è®­ç»ƒæƒé‡
model = UniSTGCN(parts=['body', 'left', 'right'])
checkpoint = torch.load('pretrained_model.pth')
model.load_state_dict(checkpoint, strict=False)

# å†»ç»“æŸäº›å±‚
for name, param in model.named_parameters():
    if 'spatial_gcns' in name:
        param.requires_grad = False  # å†»ç»“ç©ºé—´GCN

# åªè®­ç»ƒæ—¶é—´GCNå’Œåˆ†ç±»å™¨
optimizer = torch.optim.Adam(
    filter(lambda p: p.requires_grad, model.parameters()),
    lr=1e-4
)
```

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

ä¸åŒæ ¼å¼çš„æ€§èƒ½å¯¹æ¯”ï¼ˆå‚è€ƒæ•°æ®ï¼‰ï¼š

| æ ¼å¼ | æå–æ—¶é—´ | æ¨ç†æ—¶é—´ | å†…å­˜å ç”¨ |
|------|---------|----------|----------|
| æ‰‹åŠ¨æå– | ~2ms | ~15ms | è¾ƒä½ |
| Auto-convert | ~0.5ms | ~16ms | ä¸­ç­‰ |
| é¢„æå–ç¼“å­˜ | ~0.1ms | ~15ms | è¾ƒé«˜ |

å»ºè®®ï¼š
- **è®­ç»ƒæ—¶**: ä½¿ç”¨é¢„æå–ç¼“å­˜ï¼Œå‡å°‘é‡å¤è®¡ç®—
- **æ¨ç†æ—¶**: ä½¿ç”¨auto_convertï¼Œä»£ç ç®€æ´
- **å†…å­˜å—é™**: ä½¿ç”¨æ‰‹åŠ¨æå–ï¼Œç²¾ç¡®æ§åˆ¶

è¿™ä¸ªç³»ç»Ÿè®¾è®¡è®©ä½ å¯ä»¥çµæ´»åœ°ä½¿ç”¨å„ç§å…³é”®ç‚¹æ ¼å¼ï¼ŒåŒæ—¶ä¿æŒä»£ç çš„ç®€æ´æ€§å’Œé«˜æ€§èƒ½ï¼