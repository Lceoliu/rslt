train:
  seed: 3407
  epochs: 5
  log_interval: 10
  val_interval: 100
  save_dir: runs/ckpts
  save_dir_root: runs
  save_every: 60           # 0 disables periodic save; otherwise save every N steps
  resume_from: ''         # set to runs/{timestamp}/checkpoints or runs/{timestamp} to resume
  # dummy_loss: none   # ignored when LLM CE loss is used

dataset:
  data_dir: /2023234331/data/csl_dental
  # Optional augmentations used by dataset/my_dataset
  augmentations: "speed"  # "speed", "mask", 
  aug_prob: 0.5
  aug_speed_min: 0.9
  aug_speed_max: 1.1
  aug_mask_prob: 0.05

model:
  parts: ["body", "face", "left_hand", "right_hand", "fullbody"]
  backbone: "aagcn"  # or "stgcn"
  part_embed_dim: 256
  out_embed_dim: 512
  drop_conf: true
  fusion: "attention"  # "attention" "concat_mlp"

data:
  batch_size: 16
  num_workers: 4
  # If dataset.data_dir is not provided, fallback dummy will be used:
  T: 32
  train_length: 256
  val_length: 128
  # custom_builder: your_module:your_builder  # returns (train_loader, val_loader, nclass)

llm:
  model_name_or_path: /workspace/Qwen
  trust_remote_code: true
  max_text_len: 128
  num_prefix_tokens: 1
  adapter_hidden: 512
  freeze_lm: false
  gradient_checkpointing: false
  bot_token: "<BOT>"

streaming:
  enabled: true
  window: 10
  stride: 5
  drop_last: true
  loss_reduction: mean

nclass: 10
