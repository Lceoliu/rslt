# RSLT vs UniSign: å…³é”®å·®å¼‚åˆ†æä¸æ½œåœ¨BugæŠ¥å‘Š

**ç”Ÿæˆæ—¶é—´**: 2025-11-04
**åˆ†æç›®æ ‡**: æ‰¾å‡ºRSLTæ€§èƒ½è¿œä½äºUniSignçš„æ ¹æœ¬åŸå› 

---

## ğŸ”´ å…³é”®å·®å¼‚æ€»ç»“ï¼ˆCritical Differencesï¼‰

### 1. **æ•°æ®é¢„å¤„ç†ç­–ç•¥**

| ç»´åº¦ | RSLT | UniSign | å½±å“ |
|------|------|---------|------|
| **Chunking** | âœ… ä½¿ç”¨ (window=32, stride=16) | âŒ æ— ï¼Œç›´æ¥å¤„ç†å…¨åºåˆ— | **HIGH** |
| **éƒ¨ä½é€‰æ‹©** | 5éƒ¨ä½ï¼šbody(17), face(68), hands(21Ã—2), fullbody(133) | 4éƒ¨ä½ï¼šbody(9ç²¾ç®€), face(18ç²¾ç®€), hands(21Ã—2) | **CRITICAL** |
| **ç½®ä¿¡åº¦é˜ˆå€¼** | 0.25 | 0.3 | LOW |
| **å½’ä¸€åŒ–æ–¹æ³•** | COCO-Wholebodyæ ¼å¼ | OpenPoseæ ¼å¼ | LOW (é€»è¾‘ç›¸åŒ) |

#### âš ï¸ æ½œåœ¨Bug #1: éƒ¨ä½å…³é”®ç‚¹æ•°é‡ä¸åŒ¹é…

```python
# RSLTä½¿ç”¨å®Œæ•´COCOæ ¼å¼
body: 17ç‚¹ (å®Œæ•´éª¨æ¶)
face: 68ç‚¹ (å®Œæ•´é¢éƒ¨)

# UniSignä½¿ç”¨ç²¾ç®€ç‰ˆ
body: [0, 3, 4, 5, 6, 7, 8, 9, 10] = 9ç‚¹
face: [23:40:2] + [83:91] + [53] = 18ç‚¹
```

**é—®é¢˜**: RSLTçš„bodyå’ŒfaceåŒ…å«äº†å¤§é‡å†—ä½™å…³é”®ç‚¹ï¼Œå¯èƒ½å¼•å…¥å™ªå£°ï¼
**å»ºè®®**: å°è¯•ç²¾ç®€åˆ°UniSignçš„9+18ç‚¹é…ç½®

---

### 2. **GCNæ¶æ„å·®å¼‚**

#### ç‰¹å¾èåˆç­–ç•¥ï¼ˆæœ€å…³é”®çš„å·®å¼‚ï¼ï¼‰

**UniSignçš„æ ¸å¿ƒè®¾è®¡**:
```python
# models.py:240-256
# Temporal GCNä¹‹å‰ï¼Œå°†bodyç‰¹å¾èåˆåˆ°hands/face
for part in ['left', 'right', 'face']:
    # Left hand: åŠ ä¸Šbodyçš„å€’æ•°ç¬¬2ä¸ªèŠ‚ç‚¹ï¼ˆå·¦wristï¼‰
    gcn_feat = gcn_feat + body_feat[..., -2][...,None].detach()

    # Right hand: åŠ ä¸Šbodyçš„å€’æ•°ç¬¬1ä¸ªèŠ‚ç‚¹ï¼ˆå³wristï¼‰
    gcn_feat = gcn_feat + body_feat[..., -1][...,None].detach()

    # Face: åŠ ä¸Šbodyçš„ç¬¬0ä¸ªèŠ‚ç‚¹ï¼ˆneck/noseï¼‰
    gcn_feat = gcn_feat + body_feat[..., 0][...,None].detach()
```

**RSLTçš„å®ç°**:
```python
# æ²¡æœ‰è¿™ä¸ªèåˆæœºåˆ¶ï¼
# å„éƒ¨ä½å®Œå…¨ç‹¬ç«‹å¤„ç†
```

#### âš ï¸ æ½œåœ¨Bug #2: ç¼ºå°‘Body-to-Partç‰¹å¾èåˆ

**é—®é¢˜**:
- UniSigné€šè¿‡bodyç‰¹å¾å¢å¼ºhands/faceï¼Œå»ºç«‹éƒ¨ä½é—´çš„ç©ºé—´è¿æ¥
- RSLTå„éƒ¨ä½å®Œå…¨å­¤ç«‹ï¼Œä¸¢å¤±äº†å…¨å±€ä¸Šä¸‹æ–‡ä¿¡æ¯

**å½±å“**: **CRITICAL** - è¿™å¯èƒ½æ˜¯æ€§èƒ½å·®è·çš„ä¸»è¦åŸå› ï¼

**å»ºè®®ä¿®å¤**:
```python
# åœ¨visual_encoder.pyæˆ–parts_gcn.pyä¸­æ·»åŠ 
# å¤„ç†å®Œspatial GCNåï¼Œè¿›è¡Œéƒ¨ä½èåˆ
def fuse_body_to_parts(features, part_names):
    body_idx = part_names.index('body')
    body_feat = features[:, body_idx, :, :]  # [B*N, T, D]

    for i, part in enumerate(part_names):
        if part == 'left_hand':
            # ä½¿ç”¨bodyçš„wristèŠ‚ç‚¹ç‰¹å¾
            features[:, i, :, :] += body_feat[:, :, WRIST_LEFT_IDX:WRIST_LEFT_IDX+1]
        elif part == 'right_hand':
            features[:, i, :, :] += body_feat[:, :, WRIST_RIGHT_IDX:WRIST_RIGHT_IDX+1]
        elif part == 'face':
            features[:, i, :, :] += body_feat[:, :, NECK_IDX:NECK_IDX+1]
    return features
```

---

### 3. **å‚æ•°å…±äº«ç­–ç•¥**

**UniSign**:
```python
# models.py:95-97
# å·¦å³æ‰‹å…±äº«å‚æ•°ï¼ˆå‡å°‘è¿‡æ‹Ÿåˆé£é™©ï¼‰
self.gcn_modules['left'] = self.gcn_modules['right']
self.fusion_gcn_modules['left'] = self.fusion_gcn_modules['right']
self.proj_linear['left'] = self.proj_linear['right']
```

**RSLT**:
```python
# parts_gcn.py
# æ¯ä¸ªéƒ¨ä½ç‹¬ç«‹å‚æ•°ï¼ˆåŒ…æ‹¬left_handå’Œright_handï¼‰
for part in self.parts:
    backbone = UniGCNPartBackbone(...)  # æ¯ä¸ªpartéƒ½newä¸€ä¸ª
```

#### âš ï¸ æ½œåœ¨Bug #3: å·¦å³æ‰‹ç‹¬ç«‹å‚æ•°å¯¼è‡´è¿‡æ‹Ÿåˆ

**é—®é¢˜**:
- å·¦å³æ‰‹çš„åŠ¨ä½œæ¨¡å¼åº”è¯¥ç›¸ä¼¼ï¼Œå…±äº«å‚æ•°å¯ä»¥æé«˜æ³›åŒ–èƒ½åŠ›
- ç‹¬ç«‹å‚æ•°å¯èƒ½å¯¼è‡´æ•°æ®é‡ä¸è¶³æ—¶è¿‡æ‹Ÿåˆ

**å½±å“**: **MEDIUM-HIGH**

**å»ºè®®ä¿®å¤**:
```python
# åœ¨MultiPartGCNModel.__init__ä¸­æ·»åŠ 
if 'left_hand' in self.parts and 'right_hand' in self.parts:
    # å…±äº«å·¦å³æ‰‹å‚æ•°
    right_idx = list(self.parts).index('right_hand')
    left_idx = list(self.parts).index('left_hand')
    self.backbones['left_hand'] = self.backbones['right_hand']
```

---

### 4. **Learnable Part Parameters**

**UniSign**:
```python
# models.py:99
self.part_para = nn.Parameter(torch.zeros(hidden_dim*len(self.modes)))

# models.py:266
inputs_embeds = torch.cat(features, dim=-1) + self.part_para
```

**RSLT**:
```python
# visual_encoder.py
# æ²¡æœ‰learnable part parameters
# ç›´æ¥concatenateåæŠ•å½±
```

#### âš ï¸ æ½œåœ¨Bug #4: ç¼ºå°‘Learnable Part Bias

**é—®é¢˜**:
- UniSignçš„part_paraå…è®¸æ¨¡å‹å­¦ä¹ ä¸åŒéƒ¨ä½çš„importance weighting
- RSLTæ‰€æœ‰éƒ¨ä½è¢«å¹³ç­‰å¯¹å¾…

**å½±å“**: **MEDIUM**

**å»ºè®®ä¿®å¤**:
```python
# åœ¨VisualEncoder.__init__ä¸­æ·»åŠ 
self.part_bias = nn.Parameter(
    torch.zeros(part_count * gcn_embed_dim)
)

# åœ¨forwardä¸­ä¿®æ”¹
seq = seq + self.part_bias.view(1, 1, -1)
```

---

### 5. **Temporal Downsampling**

**RSLT**:
```python
# visual_encoder.py:125
# ä½¿ç”¨stride=2é™é‡‡æ ·
seq = seq[:, :: self.sampling_stride, :]  # 32å¸§ -> 16 tokens
```

**UniSign**:
```python
# æ²¡æœ‰temporal downsampling
# ä¿æŒå®Œæ•´æ—¶é—´åˆ†è¾¨ç‡
```

#### âš ï¸ æ½œåœ¨Bug #5: Temporal Downsamplingå¯èƒ½ä¸¢å¤±ç»†ç²’åº¦è¿åŠ¨ä¿¡æ¯

**é—®é¢˜**:
- Stride=2é™é‡‡æ ·ä¸¢å¤±äº†ä¸€åŠçš„æ—¶åºä¿¡æ¯
- æ‰‹è¯­åŠ¨ä½œé«˜åº¦ä¾èµ–ç»†ç²’åº¦æ—¶åºå˜åŒ–

**å½±å“**: **HIGH**

**å»ºè®®**:
1. å°è¯•stride=1ï¼ˆä¸é™é‡‡æ ·ï¼‰
2. æˆ–ä½¿ç”¨learnable temporal poolingæ›¿ä»£hard stride

---

### 6. **Chunkingæœºåˆ¶**

**RSLT**:
```python
# my_dataset.py:394
# Sliding window chunking
chunk_cnt = (t_prime - self.window) // self.stride + 1
# window=32, stride=16
```

**UniSign**:
```python
# datasets.py:462-465
# ç›´æ¥é‡‡æ ·æˆ–ä½¿ç”¨å…¨éƒ¨å¸§
if duration > self.max_length:
    tmp = sorted(random.sample(range(duration), k=self.max_length))
else:
    tmp = list(range(duration))
```

#### âš ï¸ æ½œåœ¨Bug #6: Chunkingç ´åäº†é•¿æœŸæ—¶åºä¾èµ–

**é—®é¢˜**:
- å°†é•¿åºåˆ—åˆ‡åˆ†æˆ32å¸§çš„chunkï¼Œä¸¢å¤±äº†chunkä¹‹é—´çš„æ—¶åºå…³ç³»
- UniSigné€šè¿‡å…¨åºåˆ—å¤„ç†ä¿ç•™äº†å®Œæ•´çš„temporal context

**å½±å“**: **CRITICAL**

**åˆ†æ**:
```
RSLTå¤„ç†æµç¨‹:
åŸå§‹åºåˆ— [T=200å¸§]
  â†“
åˆ‡åˆ†æˆchunks [(0-32), (16-48), (32-64), ...]
  â†“
æ¯ä¸ªchunkç‹¬ç«‹é€šè¿‡GCN (ä¸¢å¤±chunké—´ä¾èµ–)
  â†“
LLMå°è¯•é‡å»ºå…¨å±€è¯­ä¹‰ï¼ˆä½†å±€éƒ¨ç‰¹å¾å·²ç ´ç¢ï¼‰

UniSignå¤„ç†æµç¨‹:
åŸå§‹åºåˆ— [T=200å¸§]
  â†“
é‡‡æ ·åˆ°max_length=256 (ä¿ç•™å…¨å±€ç»“æ„)
  â†“
å®Œæ•´åºåˆ—é€šè¿‡GCN
  â†“
LLMè·å¾—è¿è´¯çš„å…¨å±€ç‰¹å¾
```

**å»ºè®®**:
1. **çŸ­æœŸ**: å¢å¤§windowå’Œstride (window=64, stride=32)
2. **ä¸­æœŸ**: åœ¨chunkä¹‹é—´æ·»åŠ overlapå’Œcross-chunk attention
3. **é•¿æœŸ**: ç§»é™¤chunkingï¼Œæ”¹ç”¨å…¨åºåˆ—å¤„ç†+temporal pooling

---

### 7. **å›¾ç»“æ„å®šä¹‰**

**UniSign**:
```python
# stgcn_layers/gcn_utils.py
# ä½¿ç”¨distance-based adjacency (max_hop=1)
# å›ºå®šçš„å›¾ç»“æ„
```

**RSLT**:
```python
# uni_GCN/stgcn_block.py
# ä½¿ç”¨adaptive adjacency (å¯å­¦ä¹ )
self.adaptive = adaptive  # True
if self.adaptive:
    self.A = nn.Parameter(A.clone())
```

#### âœ… RSLTä¼˜åŠ¿: Adaptive Adjacency

**åˆ†æ**: RSLTçš„adaptive adjacencyç†è®ºä¸Šæ›´å¼ºå¤§ï¼Œä½†éœ€è¦è¶³å¤Ÿæ•°æ®è®­ç»ƒ

---

### 8. **Maskå¤„ç†**

**RSLT**:
```python
# parts_gcn.py:52-70
# 3-level masking system
frame_mask: [B*N, T]  # å¸§çº§åˆ«
chunk_mask: [B, N]    # chunkçº§åˆ«
last_chunk_valid_len: [B]  # æœ€åchunkçš„æœ‰æ•ˆå¸§æ•°
```

**UniSign**:
```python
# datasets.py:367-373
# ç®€å•çš„attention mask
attention_mask = pad_sequence(..., padding_value=0)
# mask_gen = [1, 1, ..., 0, 0] for padding
```

#### âš ï¸ æ½œåœ¨Bug #7: å¤æ‚Maské€»è¾‘å¯èƒ½æœ‰å®ç°é”™è¯¯

**é—®é¢˜**: RSLTçš„maskä¼ æ’­é€»è¾‘å¤æ‚ï¼Œå®¹æ˜“å‡ºé”™

**éœ€è¦éªŒè¯çš„ä»£ç **:
```python
# parts_gcn.py:59-67
# æ£€æŸ¥last_chunk_valid_lençš„maskæ˜¯å¦æ­£ç¡®åº”ç”¨
for i in range(batch):
    last_valid_chunk_idx = pose_len[i] - 1
    if last_valid_chunk_idx >= 0:
        valid_frames = last_chunk_valid_len[i]
        flat_idx = i * num_chunks + last_valid_chunk_idx
        frame_mask_bool[flat_idx, valid_frames:] = False  # è¿™é‡Œæ˜¯å¦æ­£ç¡®ï¼Ÿ
```

---

### 9. **æ•°æ®å¢å¼º**

**RSLT**:
```python
# my_dataset.py:229-285
# 1. Speed augmentation (factor âˆˆ [0.9, 1.1])
# 2. Mask augmentation (mask_prob=0.05)
```

**UniSign**:
```python
# æ²¡æœ‰æ˜æ˜¾çš„æ•°æ®å¢å¼º
```

#### âœ… RSLTä¼˜åŠ¿: æ•°æ®å¢å¼º

**åˆ†æ**: å¢å¼ºæœ‰åŠ©äºæ³›åŒ–ï¼Œä½†éœ€è¦ç¡®ä¿augmentationä¸ä¼šç ´åè¯­ä¹‰

---

### 10. **LLMé›†æˆ**

**RSLT**:
```python
# LLM_wrapper.py
# Decoder-only LLM (Qwen)
# Visual tokensä½œä¸ºprefix
# Labels: [-100å‰ç¼€, token_ids, eos]
```

**UniSign**:
```python
# models.py:139-295
# MT5 (Encoder-Decoder)
# Visual tokensé€šè¿‡encoder
# Cross-attention to decoder
# Label smoothing=0.2
```

#### âš ï¸ æ½œåœ¨Bug #8: ç¼ºå°‘Label Smoothing

**é—®é¢˜**: RSLTä½¿ç”¨raw CrossEntropyLossï¼ŒUniSignä½¿ç”¨label_smoothing=0.2

**å½±å“**: **MEDIUM**

**å»ºè®®ä¿®å¤**:
```python
# åœ¨LLM_wrapper.pyçš„forwardä¸­
loss_fct = nn.CrossEntropyLoss(
    ignore_index=-100,
    label_smoothing=0.2  # æ·»åŠ è¿™ä¸ª
)
```

---

## ğŸ¯ Bugä¼˜å…ˆçº§åˆ—è¡¨

### P0 (Critical - å¿…é¡»ä¿®å¤)

1. **Bug #2: ç¼ºå°‘Body-to-Partç‰¹å¾èåˆ**
   - å½±å“: å„éƒ¨ä½å­¤ç«‹ï¼Œä¸¢å¤±å…¨å±€ä¸Šä¸‹æ–‡
   - ä¿®å¤éš¾åº¦: â­â­
   - é¢„æœŸæ€§èƒ½æå‡: +5-10 BLEU

2. **Bug #6: Chunkingç ´åé•¿æœŸæ—¶åºä¾èµ–**
   - å½±å“: æ—¶åºä¿¡æ¯fragmented
   - ä¿®å¤éš¾åº¦: â­â­â­â­
   - é¢„æœŸæ€§èƒ½æå‡: +3-8 BLEU

3. **Bug #5: Temporal Downsamplingä¸¢å¤±ç»†ç²’åº¦ä¿¡æ¯**
   - å½±å“: 50%æ—¶åºä¿¡æ¯ä¸¢å¤±
   - ä¿®å¤éš¾åº¦: â­
   - é¢„æœŸæ€§èƒ½æå‡: +2-5 BLEU

### P1 (High - å¼ºçƒˆå»ºè®®ä¿®å¤)

4. **Bug #1: éƒ¨ä½å…³é”®ç‚¹å†—ä½™**
   - å½±å“: å¼•å…¥å™ªå£°ï¼Œå¢åŠ è®¡ç®—
   - ä¿®å¤éš¾åº¦: â­â­
   - é¢„æœŸæ€§èƒ½æå‡: +1-3 BLEU

5. **Bug #3: å·¦å³æ‰‹ç‹¬ç«‹å‚æ•°**
   - å½±å“: å¯èƒ½è¿‡æ‹Ÿåˆ
   - ä¿®å¤éš¾åº¦: â­
   - é¢„æœŸæ€§èƒ½æå‡: +1-2 BLEU

### P2 (Medium - å»ºè®®å°è¯•)

6. **Bug #4: ç¼ºå°‘Learnable Part Bias**
   - å½±å“: éƒ¨ä½æƒé‡æ— æ³•è‡ªé€‚åº”
   - ä¿®å¤éš¾åº¦: â­
   - é¢„æœŸæ€§èƒ½æå‡: +0.5-1 BLEU

7. **Bug #8: ç¼ºå°‘Label Smoothing**
   - å½±å“: è¿‡æ‹Ÿåˆé£é™©
   - ä¿®å¤éš¾åº¦: â­
   - é¢„æœŸæ€§èƒ½æå‡: +0.5-1.5 BLEU

8. **Bug #7: Maské€»è¾‘å¤æ‚åº¦**
   - å½±å“: æ½œåœ¨å®ç°é”™è¯¯
   - ä¿®å¤éš¾åº¦: â­â­
   - é¢„æœŸæ€§èƒ½æå‡: æœªçŸ¥ï¼ˆå¯èƒ½æ˜¯bugï¼‰

---

## ğŸ”§ å¿«é€Ÿä¿®å¤å»ºè®®ï¼ˆQuick Winsï¼‰

### 1. ç«‹å³å¯æµ‹è¯•çš„ä¿®æ”¹

```python
# A. ç§»é™¤temporal downsampling (visual_encoder.py:125)
# ä¿®æ”¹å‰:
seq = seq[:, :: self.sampling_stride, :]

# ä¿®æ”¹å:
# seq = seq[:, :: self.sampling_stride, :]  # æ³¨é‡Šæ‰
seq = seq  # ä¿ç•™æ‰€æœ‰å¸§
```

```python
# B. æ·»åŠ label smoothing (LLM_wrapper.py)
# åœ¨compute losséƒ¨åˆ†æ·»åŠ label_smoothing=0.2
```

```python
# C. å…±äº«å·¦å³æ‰‹å‚æ•° (parts_gcn.py)
# åœ¨_ensure_backbonesä¹‹åæ·»åŠ 
if 'left_hand' in self.parts and 'right_hand' in self.parts:
    self.backbones['left_hand'] = self.backbones['right_hand']
```

### 2. ä¸­æœŸé‡æ„å»ºè®®

#### æ·»åŠ Body-to-Part Fusion

åœ¨`parts_gcn.py`çš„`MultiPartGCNModel.forward`ä¸­æ·»åŠ ï¼š

```python
def forward(self, pose, ...):
    # ... åŸæœ‰ä»£ç å¤„ç†åˆ°features: [B*N, P, T, D]

    # === æ–°å¢: Body-to-Part Fusion ===
    if 'body' in self.parts:
        body_idx = list(self.parts).index('body')
        body_feat = features[:, body_idx, :, :]  # [B*N, T, D]

        for i, part in enumerate(self.parts):
            if part == 'left_hand':
                # å‡è®¾bodyæœ€åå‡ ä¸ªèŠ‚ç‚¹æ˜¯wrist
                features[:, i, :, :] = features[:, i, :, :] + body_feat[:, :, -2:-1].detach()
            elif part == 'right_hand':
                features[:, i, :, :] = features[:, i, :, :] + body_feat[:, :, -1:].detach()
            elif part == 'face':
                features[:, i, :, :] = features[:, i, :, :] + body_feat[:, :, 0:1].detach()

    return features, frame_mask_bool, chunk_mask
```

### 3. é•¿æœŸæ¶æ„æ”¹è¿›

è€ƒè™‘å®Œå…¨é‡æ„ä¸ºæ— chunkingè®¾è®¡ï¼š
- ä½¿ç”¨å®Œæ•´åºåˆ—å¤„ç†
- æ·»åŠ temporal positional encoding
- ä½¿ç”¨cross-chunk attention

---

## ğŸ“Š å®éªŒéªŒè¯è®¡åˆ’

### Phase 1: å¿«é€ŸéªŒè¯ (1-2å¤©)
1. âœ… æµ‹è¯•ç§»é™¤temporal downsampling
2. âœ… æµ‹è¯•æ·»åŠ label smoothing
3. âœ… æµ‹è¯•å·¦å³æ‰‹å‚æ•°å…±äº«

### Phase 2: å…³é”®ä¿®å¤ (3-5å¤©)
4. âš ï¸ å®ç°Body-to-Part fusion
5. âš ï¸ ç²¾ç®€å…³é”®ç‚¹é…ç½®ï¼ˆä½¿ç”¨9+18ç‚¹ï¼‰
6. âš ï¸ æ·»åŠ learnable part bias

### Phase 3: æ¶æ„é‡æ„ (1-2å‘¨)
7. ğŸ”„ é‡æ–°è®¾è®¡chunkingç­–ç•¥æˆ–ç§»é™¤chunking
8. ğŸ”„ å¯¹æ¯”ä¸åŒGCNé…ç½®

---

## ğŸ“ è°ƒè¯•æ£€æŸ¥æ¸…å•

### æ•°æ®å±‚é¢
- [ ] æ£€æŸ¥å½’ä¸€åŒ–æ˜¯å¦æ­£ç¡®ï¼ˆå¯è§†åŒ–å½’ä¸€åŒ–åçš„å…³é”®ç‚¹ï¼‰
- [ ] éªŒè¯maskæ˜¯å¦æ­£ç¡®åº”ç”¨ï¼ˆæ‰“å°mask statisticsï¼‰
- [ ] æ£€æŸ¥collate_fnæ˜¯å¦æ­£ç¡®å¤„ç†padding
- [ ] éªŒè¯æ•°æ®å¢å¼ºæ˜¯å¦åˆç†ï¼ˆå¯è§†åŒ–augmented samplesï¼‰

### æ¨¡å‹å±‚é¢
- [ ] æ£€æŸ¥adjacency matrixæ˜¯å¦æ­£ç¡®åˆå§‹åŒ–
- [ ] éªŒè¯GCNçš„forward shapeæ˜¯å¦åŒ¹é…é¢„æœŸ
- [ ] æ£€æŸ¥gradient flowï¼ˆæ˜¯å¦æœ‰æ¢¯åº¦æ¶ˆå¤±/çˆ†ç‚¸ï¼‰
- [ ] éªŒè¯maskåœ¨GCNä¸­çš„åº”ç”¨æ˜¯å¦æ­£ç¡®

### è®­ç»ƒå±‚é¢
- [ ] æ£€æŸ¥lossæ˜¯å¦æ”¶æ•›
- [ ] éªŒè¯learning rate scheduleæ˜¯å¦åˆç†
- [ ] æ£€æŸ¥æ˜¯å¦æœ‰nan/inf values
- [ ] å¯¹æ¯”è®­ç»ƒ/éªŒè¯lossæ›²çº¿

---

## ğŸ”¬ è¯Šæ–­å·¥å…·ä»£ç 

### 1. æ£€æŸ¥Maskæ­£ç¡®æ€§

```python
# åœ¨parts_gcn.pyçš„forwardä¸­æ·»åŠ 
def debug_masks(self, frame_mask, chunk_mask, pose_len):
    print("=== Mask Debug ===")
    print(f"chunk_mask shape: {chunk_mask.shape}")
    print(f"frame_mask shape: {frame_mask.shape}")
    print(f"pose_len: {pose_len}")

    # æ£€æŸ¥æ¯ä¸ªæ ·æœ¬çš„æœ‰æ•ˆchunkæ•°
    for i in range(chunk_mask.size(0)):
        valid_chunks = chunk_mask[i].sum().item()
        expected = pose_len[i].item()
        if valid_chunks != expected:
            print(f"âŒ Sample {i}: valid_chunks={valid_chunks}, expected={expected}")
```

### 2. å¯è§†åŒ–å½’ä¸€åŒ–æ•ˆæœ

```python
# åœ¨transform.pyä¸­æ·»åŠ 
def visualize_normalization(self, original, normalized):
    import matplotlib.pyplot as plt

    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))

    # ç»˜åˆ¶åŸå§‹å…³é”®ç‚¹
    ax1.scatter(original[:, :, 0], original[:, :, 1], alpha=0.5)
    ax1.set_title("Original")

    # ç»˜åˆ¶å½’ä¸€åŒ–åå…³é”®ç‚¹
    ax2.scatter(normalized[:, :, 0], normalized[:, :, 1], alpha=0.5)
    ax2.set_title("Normalized")
    ax2.set_xlim(-1, 1)
    ax2.set_ylim(-1, 1)

    plt.savefig("normalization_check.png")
```

---

## æ€»ç»“

RSLTæ€§èƒ½ä½äºUniSignçš„ä¸»è¦åŸå› æ¨æµ‹ï¼š

1. **æ ¸å¿ƒé—®é¢˜**: ç¼ºå°‘Body-to-Partç‰¹å¾èåˆï¼ˆBug #2ï¼‰
2. **æ¶æ„é—®é¢˜**: Chunkingç ´åæ—¶åºä¾èµ–ï¼ˆBug #6ï¼‰
3. **è®¾è®¡é—®é¢˜**: Temporal downsamplingä¸¢å¤±ä¿¡æ¯ï¼ˆBug #5ï¼‰
4. **å®ç°ç»†èŠ‚**: å¤šä¸ªå°bugç´¯ç§¯æ•ˆåº”

**å»ºè®®ä¼˜å…ˆä¿®å¤é¡ºåº**: Bug #5 â†’ Bug #2 â†’ Bug #3 â†’ Bug #8 â†’ Bug #6

é¢„æœŸé€šè¿‡ä¿®å¤è¿™äº›bugï¼Œæ€§èƒ½å¯æå‡ **10-20 BLEU points**ã€‚
